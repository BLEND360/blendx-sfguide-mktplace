name: Deploy to QA

on:
  push:
    branches:
      - qa
  workflow_dispatch:

env:
  BACKEND_IMAGE: eap_backend
  FRONTEND_IMAGE: eap_frontend
  ROUTER_IMAGE: eap_router
  SNOWFLAKE_CONNECTION: ${{ vars.SNOWFLAKE_CONNECTION }}

jobs:
  # ============================================
  # VALIDATE
  # ============================================
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate YAML templates
        run: |
          echo "Validating YAML files..."
          python3 -c "
          import yaml
          import sys
          files = ['templates/manifest_template.yml', 'templates/fullstack_template.yaml']
          errors = []
          for f in files:
              try:
                  with open(f) as fh:
                      yaml.safe_load(fh)
                  print(f'OK: {f}')
              except Exception as e:
                  errors.append(f'{f}: {e}')
                  print(f'FAIL: {f}: {e}')
          if errors:
              sys.exit(1)
          "

      - name: Validate SQL syntax (basic)
        run: |
          echo "Checking SQL files for basic syntax..."
          for f in scripts/sql/*.sql templates/*.sql; do
            if [ -f "$f" ]; then
              # Check for unclosed parentheses, missing semicolons at end
              if grep -qE "^[^-]*\([^)]*$" "$f" 2>/dev/null; then
                echo "WARNING: Possible unclosed parenthesis in $f"
              fi
              echo "OK: $f"
            fi
          done

      - name: Validate requirements.txt is in sync with pyproject.toml
        run: |
          echo "Checking if requirements.txt is in sync with pyproject.toml..."
          cd backend

          # Install uv if not available
          if ! command -v uv &> /dev/null; then
            curl -LsSf https://astral.sh/uv/install.sh | sh
            export PATH="$HOME/.local/bin:$PATH"
          fi

          # Generate fresh requirements.txt to a temp file
          uv export --no-hashes --no-dev -o /tmp/requirements-check.txt 2>/dev/null

          # Compare with committed version (ignore comment lines that may have timestamps)
          if ! diff -q <(grep -v "^#" requirements.txt | sort) <(grep -v "^#" /tmp/requirements-check.txt | sort) > /dev/null 2>&1; then
            echo "::error::requirements.txt is out of sync with pyproject.toml"
            echo ""
            echo "Differences found:"
            diff <(grep -v "^#" requirements.txt | sort) <(grep -v "^#" /tmp/requirements-check.txt | sort) || true
            echo ""
            echo "To fix, run: make dev-requirements (or: cd backend && uv export --no-hashes --no-dev -o requirements.txt)"
            exit 1
          fi

          echo "✓ requirements.txt is in sync with pyproject.toml"

      - name: Validate Alembic migrations have SQL files
        run: |
          echo "Checking that all Alembic migrations have corresponding SQL files..."

          MIGRATIONS_DIR="scripts/sql/migrations"
          ALEMBIC_DIR="backend/alembic/versions"
          ERRORS=0

          # Get all alembic migration revision IDs from the Python files
          for alembic_file in "$ALEMBIC_DIR"/*.py; do
            if [ -f "$alembic_file" ]; then
              filename=$(basename "$alembic_file")

              # Skip __pycache__ and __init__.py
              if [[ "$filename" == "__init__.py" ]] || [[ "$filename" == "__pycache__" ]]; then
                continue
              fi

              # Extract revision ID from inside the Python file (revision = '...' or revision: str = '...')
              revision_id=$(grep -E "^revision\s*(:\s*str)?\s*=\s*['\"]" "$alembic_file" | sed -E "s/.*['\"]([^'\"]+)['\"].*/\1/")

              if [ -z "$revision_id" ]; then
                echo "::warning::Could not extract revision ID from: $filename"
                continue
              fi

              # Check if any SQL file contains this revision ID (in the migration header or version insert)
              found=false
              for sql_file in "$MIGRATIONS_DIR"/*.sql; do
                if [ -f "$sql_file" ]; then
                  if grep -q "Migration: $revision_id" "$sql_file" || grep -q "version_num = '$revision_id'" "$sql_file"; then
                    echo "OK: $filename (revision: $revision_id) -> $(basename "$sql_file")"
                    found=true
                    break
                  fi
                fi
              done

              if [ "$found" = false ]; then
                echo "::error::Missing SQL file for migration: $filename (revision: $revision_id)"
                echo "  Run: python scripts/generate/generate_migrations_sql.py"
                ERRORS=$((ERRORS + 1))
              fi
            fi
          done

          if [ $ERRORS -gt 0 ]; then
            echo ""
            echo "::error::Found $ERRORS Alembic migrations without corresponding SQL files."
            echo "Run 'python scripts/generate/generate_migrations_sql.py' to generate the SQL files."
            exit 1
          fi

          echo "All Alembic migrations have corresponding SQL files."

  # ============================================
  # TEST: Run backend tests
  # ============================================
  test:
    runs-on: ubuntu-latest
    needs: [validate]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Set up Python
        run: uv python install 3.10

      - name: Install dependencies
        working-directory: backend
        run: uv sync --dev

      - name: Run tests
        working-directory: backend
        run: uv run pytest -v --tb=short

  # ============================================
  # PREFLIGHT: Ensure commits passed through develop before any build
  # ============================================
  preflight:
    runs-on: ubuntu-latest
    needs: [validate, test]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Ensure qa is updated via merge from develop
        run: |
          echo "Validating that qa was updated via merge from develop..."

          git fetch origin develop qa

          DEVELOP_HEAD=$(git rev-parse origin/develop)
          QA_HEAD=$(git rev-parse HEAD)

          echo "Develop HEAD: $DEVELOP_HEAD"
          echo "QA HEAD:      $QA_HEAD"

          # 1) develop HEAD must be included in qa
          if ! git merge-base --is-ancestor "$DEVELOP_HEAD" "$QA_HEAD"; then
            echo "::error::QA is missing commits from develop. Merge develop into qa first."
            exit 1
          fi

          # 2) last integration must be a merge commit from develop
          LAST_MERGE=$(git log --merges --oneline origin/develop..HEAD | head -n 1)

          if [ -z "$LAST_MERGE" ]; then
            echo "::error::QA deployment blocked."
            echo "qa must be updated via a merge commit from develop (no direct commits allowed)."
            exit 1
          fi

          echo "✓ QA updated via merge from develop"

  # ============================================
  # PARALLEL BUILD JOBS
  # ============================================
  build-backend:
    needs: [validate, preflight]
    runs-on: ubuntu-latest
    environment: qa
    outputs:
      image-tag: ${{ steps.build.outputs.image-tag }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build and push backend image
        id: build
        uses: ./.github/actions/docker-build
        with:
          image-name: ${{ env.BACKEND_IMAGE }}
          context: ./backend
          snowflake-repo: ${{ vars.SNOWFLAKE_REPO }}
          private-key: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
          account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          user: ${{ vars.SNOWFLAKE_DEPLOY_USER }}
          role: ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}
          warehouse: ${{ vars.SNOWFLAKE_WAREHOUSE }}
          database: ${{ vars.SNOWFLAKE_DATABASE }}
          schema: ${{ vars.SNOWFLAKE_SCHEMA }}
          host: ${{ secrets.SNOWFLAKE_HOST }}
          github-sha: ${{ github.sha }}
          branch-tag: qa

  build-frontend:
    needs: [validate, preflight]
    runs-on: ubuntu-latest
    environment: qa
    outputs:
      image-tag: ${{ steps.build.outputs.image-tag }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build and push frontend image
        id: build
        uses: ./.github/actions/docker-build
        with:
          image-name: ${{ env.FRONTEND_IMAGE }}
          context: ./frontend
          snowflake-repo: ${{ vars.SNOWFLAKE_REPO }}
          private-key: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
          account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          user: ${{ vars.SNOWFLAKE_DEPLOY_USER }}
          role: ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}
          warehouse: ${{ vars.SNOWFLAKE_WAREHOUSE }}
          database: ${{ vars.SNOWFLAKE_DATABASE }}
          schema: ${{ vars.SNOWFLAKE_SCHEMA }}
          host: ${{ secrets.SNOWFLAKE_HOST }}
          github-sha: ${{ github.sha }}
          branch-tag: qa

  build-router:
    needs: [validate, preflight]
    runs-on: ubuntu-latest
    environment: qa
    outputs:
      image-tag: ${{ steps.build.outputs.image-tag }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Build and push router image
        id: build
        uses: ./.github/actions/docker-build
        with:
          image-name: ${{ env.ROUTER_IMAGE }}
          context: ./router
          snowflake-repo: ${{ vars.SNOWFLAKE_REPO }}
          private-key: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
          account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          user: ${{ vars.SNOWFLAKE_DEPLOY_USER }}
          role: ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}
          warehouse: ${{ vars.SNOWFLAKE_WAREHOUSE }}
          database: ${{ vars.SNOWFLAKE_DATABASE }}
          schema: ${{ vars.SNOWFLAKE_SCHEMA }}
          host: ${{ secrets.SNOWFLAKE_HOST }}
          github-sha: ${{ github.sha }}
          branch-tag: qa

  # ============================================
  # DEPLOY-PACKAGE: Generate and upload app files
  # ============================================
  deploy-package:
    runs-on: ubuntu-latest
    environment: qa
    needs: [validate, build-backend, build-frontend, build-router]
    outputs:
      version: ${{ steps.version.outputs.version }}
      short_sha: ${{ steps.version.outputs.short_sha }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0


      - name: Determine version from git tag
        id: version
        run: |
          LATEST_TAG=$(git describe --tags --match "v*" --abbrev=0 2>/dev/null || echo "")
          SHORT_SHA=$(echo "${{ github.sha }}" | cut -c1-7)

          if [ -n "$LATEST_TAG" ]; then
            VERSION=$(echo "$LATEST_TAG" | sed -E 's/^(v[0-9]+).*/\1/' | tr '[:lower:]' '[:upper:]')
            echo "Found git tag: $LATEST_TAG -> Using version: $VERSION"
          else
            VERSION="V1"
            echo "No git tag found. Using default version: $VERSION"
          fi

          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "short_sha=$SHORT_SHA" >> $GITHUB_OUTPUT

      - name: Setup Snowflake
        uses: ./.github/actions/snowflake-setup
        with:
          private-key: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
          account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          user: ${{ vars.SNOWFLAKE_DEPLOY_USER }}
          role: ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}
          warehouse: ${{ vars.SNOWFLAKE_WAREHOUSE }}
          database: ${{ vars.SNOWFLAKE_DATABASE }}
          schema: ${{ vars.SNOWFLAKE_SCHEMA }}
          host: ${{ secrets.SNOWFLAKE_HOST }}
          login-registry: 'false'

      - name: Generate application files from templates
        run: |
          python3 scripts/generate/generate-app-files.py \
            --image-tag "${{ steps.version.outputs.short_sha }}"

      - name: Upload application files to Snowflake stage
        env:
          SNOWFLAKE_INSECURE_MODE: "true"
          REQUESTS_CA_BUNDLE: ""
          CURL_CA_BUNDLE: ""
        run: |
          # Upload root files (excluding directories)
          snow sql --query "PUT file://${{ github.workspace }}/app/src/*.sql @${{ vars.SNOWFLAKE_DATABASE }}.${{ vars.SNOWFLAKE_SCHEMA }}.app_stage AUTO_COMPRESS=FALSE OVERWRITE=TRUE;" --connection ${{ env.SNOWFLAKE_CONNECTION }}
          snow sql --query "PUT file://${{ github.workspace }}/app/src/*.yml @${{ vars.SNOWFLAKE_DATABASE }}.${{ vars.SNOWFLAKE_SCHEMA }}.app_stage AUTO_COMPRESS=FALSE OVERWRITE=TRUE;" --connection ${{ env.SNOWFLAKE_CONNECTION }}
          snow sql --query "PUT file://${{ github.workspace }}/app/src/*.yaml @${{ vars.SNOWFLAKE_DATABASE }}.${{ vars.SNOWFLAKE_SCHEMA }}.app_stage AUTO_COMPRESS=FALSE OVERWRITE=TRUE;" --connection ${{ env.SNOWFLAKE_CONNECTION }}
          # Upload scripts/setup directory
          snow sql --query "PUT file://${{ github.workspace }}/app/src/scripts/setup/* @${{ vars.SNOWFLAKE_DATABASE }}.${{ vars.SNOWFLAKE_SCHEMA }}.app_stage/scripts/setup AUTO_COMPRESS=FALSE OVERWRITE=TRUE;" --connection ${{ env.SNOWFLAKE_CONNECTION }}

      - name: Create application package if not exists
        run: |
          echo "Creating application package if not exists..."
          snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; CREATE APPLICATION PACKAGE IF NOT EXISTS ${{ vars.SNOWFLAKE_APP_PACKAGE }} DISTRIBUTION = INTERNAL;" --connection ${{ env.SNOWFLAKE_CONNECTION }} || true

      - name: Clean up orphan versions
        run: |
          echo "Checking for orphan versions to clean up..."
          # Get versions not in any release channel (max 2 allowed)
          ORPHAN_VERSIONS=$(snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; SHOW VERSIONS IN APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }};" --connection ${{ env.SNOWFLAKE_CONNECTION }} -o json 2>/dev/null | jq -r '.[] | select(.release_channel_name == null) | .version' 2>/dev/null || echo "")

          ORPHAN_COUNT=$(echo "$ORPHAN_VERSIONS" | grep -c . || echo "0")
          echo "Found $ORPHAN_COUNT orphan versions"

          # If more than 1 orphan, deregister the oldest ones (keep 1 for new patch)
          if [ "$ORPHAN_COUNT" -gt 1 ]; then
            echo "$ORPHAN_VERSIONS" | head -n $((ORPHAN_COUNT - 1)) | while read -r ver; do
              if [ -n "$ver" ]; then
                echo "Deregistering orphan version: $ver"
                # Use DEREGISTER for packages with release channels enabled
                snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; ALTER APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }} DEREGISTER VERSION $ver;" --connection ${{ env.SNOWFLAKE_CONNECTION }} 2>/dev/null || true
              fi
            done
          fi

      - name: Register version or add patch
        id: register
        run: |
          VERSION="${{ steps.version.outputs.version }}"
          STAGE_PATH="@${{ vars.SNOWFLAKE_DATABASE }}.${{ vars.SNOWFLAKE_SCHEMA }}.app_stage"
          echo "Registering version $VERSION from $STAGE_PATH..."

          # Try to add patch first (most common case) - if version doesn't exist, it will fail
          echo "Attempting to add patch for version $VERSION..."
          ADD_PATCH_OUTPUT=$(snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; ALTER APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }} ADD PATCH FOR VERSION $VERSION USING '$STAGE_PATH';" --connection ${{ env.SNOWFLAKE_CONNECTION }} 2>&1) && ADD_PATCH_SUCCESS=true || ADD_PATCH_SUCCESS=false

          echo "Add patch output: $ADD_PATCH_OUTPUT"

          if [ "$ADD_PATCH_SUCCESS" = "true" ]; then
            echo "Successfully added new patch for version $VERSION"
          else
            # Check if error is because version doesn't exist
            if echo "$ADD_PATCH_OUTPUT" | grep -qi "does not exist"; then
              echo "Version $VERSION does not exist, creating new version..."
              snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; ALTER APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }} REGISTER VERSION $VERSION USING '$STAGE_PATH';" --connection ${{ env.SNOWFLAKE_CONNECTION }}
            else
              echo "Error adding patch: $ADD_PATCH_OUTPUT"
              exit 1
            fi
          fi

          # Get the latest patch number for this version after the operation
          echo "Getting latest patch number..."

          # Use table format and parse with grep/awk for reliability
          VERSIONS_TABLE=$(snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; SHOW VERSIONS IN APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }};" --connection ${{ env.SNOWFLAKE_CONNECTION }} 2>/dev/null || echo "")
          echo "Versions table output:"
          echo "$VERSIONS_TABLE"

          # Extract patch from pipe-separated table format: | VERSION | PATCH | ...
          NEW_PATCH=$(echo "$VERSIONS_TABLE" | grep -i "| *${VERSION} *|" | awk -F'|' '{gsub(/^[ \t]+|[ \t]+$/, "", $3); print $3}' | sort -n | tail -1)

          # Validate patch is a number
          if [ -z "$NEW_PATCH" ] || ! [[ "$NEW_PATCH" =~ ^[0-9]+$ ]]; then
            echo "Warning: Could not parse patch from table, trying JSON format..."
            VERSIONS_JSON=$(snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; SHOW VERSIONS IN APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }};" --connection ${{ env.SNOWFLAKE_CONNECTION }} -o json 2>/dev/null || echo "[]")
            echo "JSON output: $VERSIONS_JSON"
            NEW_PATCH=$(echo "$VERSIONS_JSON" | jq -r "[.[] | select(.version == \"$VERSION\") | .patch] | max // 0" 2>/dev/null || echo "0")
          fi

          # Final fallback
          if [ -z "$NEW_PATCH" ] || [ "$NEW_PATCH" = "null" ] || ! [[ "$NEW_PATCH" =~ ^[0-9]+$ ]]; then
            NEW_PATCH=0
          fi

          echo "patch=$NEW_PATCH" >> $GITHUB_OUTPUT
          echo "Registered version $VERSION patch $NEW_PATCH"

      - name: Validate QA release monotonicity
        run: |
          echo "Validating QA release monotonicity..."

          VERSION="${{ steps.version.outputs.version }}"
          PATCH="${{ steps.register.outputs.patch }}"

          # Get current QA release 
          QA_ROW=$(snow sql -q "
            USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }};
            SHOW VERSIONS IN APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }};
          " --connection ${{ env.SNOWFLAKE_CONNECTION }} \
            | grep -i "| *QA *|" \
            | tail -1 || true)

          if [ -n "$QA_ROW" ]; then
            CUR_VERSION=$(echo "$QA_ROW" | awk -F'|' '{gsub(/V/,"",$2); gsub(/ /,"",$2); print $2}')
            CUR_PATCH=$(echo "$QA_ROW" | awk -F'|' '{gsub(/ /,"",$3); print $3}')

            NEW_VERSION=$(echo "$VERSION" | sed 's/V//')
            NEW_PATCH="$PATCH"

            echo "Current QA: V$CUR_VERSION patch $CUR_PATCH"
            echo "New QA:     V$NEW_VERSION patch $NEW_PATCH"

            # Only reject if going backwards (strictly less than)
            # Equal is OK because we just registered this patch
            if [ "$NEW_VERSION" -lt "$CUR_VERSION" ] || \
               { [ "$NEW_VERSION" -eq "$CUR_VERSION" ] && [ "$NEW_PATCH" -lt "$CUR_PATCH" ]; }; then
              echo "::error::QA release regression detected. Refusing to move QA backwards."
              exit 1
            fi
          else
            echo "No existing QA release found (first deploy)."
          fi

      - name: Update QA release channel
        run: |
          VERSION="${{ steps.version.outputs.version }}"
          PATCH="${{ steps.register.outputs.patch }}"
          echo "Updating QA release channel to version $VERSION patch $PATCH..."

          # First ensure version is in QA channel
          snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; ALTER APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }} MODIFY RELEASE CHANNEL QA ADD VERSION $VERSION;" --connection ${{ env.SNOWFLAKE_CONNECTION }} 2>&1 || echo "Version may already be in QA channel (OK)"

          # Set the release directive
          snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; ALTER APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }} MODIFY RELEASE CHANNEL QA SET DEFAULT RELEASE DIRECTIVE VERSION=$VERSION PATCH=$PATCH;" --connection ${{ env.SNOWFLAKE_CONNECTION }}

          echo "QA channel updated successfully"

  # ============================================
  # UPGRADE: Upgrade application and restart service
  # ============================================
  upgrade:
    runs-on: ubuntu-latest
    environment: qa
    needs: [deploy-package]
    if: ${{ always() && needs.deploy-package.result == 'success' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Snowflake
        uses: ./.github/actions/snowflake-setup
        with:
          private-key: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
          account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          user: ${{ vars.SNOWFLAKE_DEPLOY_USER }}
          role: ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}
          warehouse: ${{ vars.SNOWFLAKE_WAREHOUSE }}
          database: ${{ vars.SNOWFLAKE_DATABASE }}
          schema: ${{ vars.SNOWFLAKE_SCHEMA }}
          host: ${{ secrets.SNOWFLAKE_HOST }}
          login-registry: 'false'

      - name: Check application exists
        run: |
          set +e
          echo "Checking for application ${{ vars.SNOWFLAKE_APP_INSTANCE }}..."

          # First set the role, then query applications separately
          snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_ROLE }};" --connection ${{ env.SNOWFLAKE_CONNECTION }}

          APP_OUTPUT=$(snow sql -q "SHOW APPLICATIONS LIKE '${{ vars.SNOWFLAKE_APP_INSTANCE }}';" \
            --connection ${{ env.SNOWFLAKE_CONNECTION }} 2>&1)

          echo "Application query output:"
          echo "$APP_OUTPUT"

          # Check if output contains "No data" or "0 Row" (no applications found)
          if echo "$APP_OUTPUT" | grep -qiE "No data|0 Row"; then
            echo "::warning::Application does not exist. Run setup/create-application.sh --env qa first."
            exit 1
          elif echo "$APP_OUTPUT" | grep -qi "error\|does not exist"; then
            echo "::warning::Error checking application or application does not exist."
            exit 1
          fi

          echo "Application exists."

      - name: Upgrade application to latest patch
        run: |
          VERSION="${{ needs.deploy-package.outputs.version }}"

          # Get the latest patch number for this version using table format parsing
          echo "Getting latest patch for version $VERSION..."

          # Use table format and parse with grep/awk for reliability
          VERSIONS_TABLE=$(snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; SHOW VERSIONS IN APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }};" --connection ${{ env.SNOWFLAKE_CONNECTION }} 2>/dev/null || echo "")
          echo "Versions table output:"
          echo "$VERSIONS_TABLE"

          # Extract patch from pipe-separated table format: | VERSION | PATCH | ...
          # Filter for our version and get the max patch
          PATCH=$(echo "$VERSIONS_TABLE" | grep -i "| *${VERSION} *|" | awk -F'|' '{gsub(/^[ \t]+|[ \t]+$/, "", $3); print $3}' | sort -n | tail -1)

          # Validate patch is a number
          if [ -z "$PATCH" ] || ! [[ "$PATCH" =~ ^[0-9]+$ ]]; then
            echo "Warning: Could not parse patch number, trying JSON format..."
            VERSIONS_JSON=$(snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}; SHOW VERSIONS IN APPLICATION PACKAGE ${{ vars.SNOWFLAKE_APP_PACKAGE }};" --connection ${{ env.SNOWFLAKE_CONNECTION }} -o json 2>/dev/null || echo "[]")
            echo "JSON output: $VERSIONS_JSON"
            PATCH=$(echo "$VERSIONS_JSON" | jq -r "[.[] | select(.version == \"$VERSION\") | .patch] | max // 0" 2>/dev/null || echo "0")
          fi

          # Final validation
          if [ -z "$PATCH" ] || [ "$PATCH" = "null" ] || ! [[ "$PATCH" =~ ^[0-9]+$ ]]; then
            echo "Error: Could not determine patch number"
            exit 1
          fi

          echo "Upgrading application ${{ vars.SNOWFLAKE_APP_INSTANCE }} to version $VERSION patch $PATCH..."
          snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_ROLE }}; ALTER APPLICATION ${{ vars.SNOWFLAKE_APP_INSTANCE }} UPGRADE USING VERSION $VERSION PATCH $PATCH;" --connection ${{ env.SNOWFLAKE_CONNECTION }}
          echo "Application upgraded successfully"

      - name: Restart service
        run: |
          export SNOWFLAKE_ROLE="${{ vars.SNOWFLAKE_ROLE }}"
          export SNOWFLAKE_APP_INSTANCE="${{ vars.SNOWFLAKE_APP_INSTANCE }}"
          export SNOWFLAKE_COMPUTE_POOL="${{ vars.SNOWFLAKE_COMPUTE_POOL }}"
          export SNOWFLAKE_CONNECTION="${{ env.SNOWFLAKE_CONNECTION }}"
          export SNOWFLAKE_ENV_PREFIX="QA"
          chmod +x scripts/deploy/manage-service.sh
          ./scripts/deploy/manage-service.sh

  # ============================================
  # VERIFY: Wait for service and get URL
  # ============================================
  verify:
    runs-on: ubuntu-latest
    environment: qa
    needs: [deploy-package, upgrade]
    if: ${{ always() && needs.upgrade.result == 'success' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Snowflake
        uses: ./.github/actions/snowflake-setup
        with:
          private-key: ${{ secrets.SNOWFLAKE_PRIVATE_KEY_RAW }}
          account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          user: ${{ vars.SNOWFLAKE_DEPLOY_USER }}
          role: ${{ vars.SNOWFLAKE_DEPLOY_ROLE }}
          warehouse: ${{ vars.SNOWFLAKE_WAREHOUSE }}
          database: ${{ vars.SNOWFLAKE_DATABASE }}
          schema: ${{ vars.SNOWFLAKE_SCHEMA }}
          host: ${{ secrets.SNOWFLAKE_HOST }}
          login-registry: 'false'

      - name: Wait for service to be ready
        run: |
          export SNOWFLAKE_ROLE="${{ vars.SNOWFLAKE_ROLE }}"
          export SNOWFLAKE_APP_INSTANCE="${{ vars.SNOWFLAKE_APP_INSTANCE }}"
          export SNOWFLAKE_CONNECTION="${{ env.SNOWFLAKE_CONNECTION }}"
          export MAX_ATTEMPTS=20
          chmod +x scripts/deploy/wait-for-service.sh
          ./scripts/deploy/wait-for-service.sh

      - name: Get Application URL
        id: url
        run: |
          set +e
          echo "Fetching application URL..."

          # Get raw output and debug
          URL_OUTPUT=$(snow sql -q "USE ROLE ${{ vars.SNOWFLAKE_ROLE }}; CALL ${{ vars.SNOWFLAKE_APP_INSTANCE }}.app_public.app_url();" \
            --connection ${{ env.SNOWFLAKE_CONNECTION }} 2>&1)

          echo "Raw output:"
          echo "$URL_OUTPUT"

          # Try to extract URL - it should contain https://
          APP_URL=$(echo "$URL_OUTPUT" | grep -oE 'https://[^[:space:]|]+' | head -1)

          if [ -z "$APP_URL" ]; then
            APP_URL="URL not available yet"
          fi

          echo ""
          echo "Application URL: $APP_URL"
          echo "app_url=$APP_URL" >> $GITHUB_OUTPUT

      - name: Deploy Summary
        env:
          SHORT_SHA: ${{ needs.deploy-package.outputs.short_sha }}
        run: |
          echo ""
          echo "=========================================="
          echo "         QA DEPLOYMENT SUMMARY"
          echo "=========================================="
          echo ""
          echo "Git Info:"
          echo "  Commit:     ${{ github.sha }}"
          echo "  Short SHA:  ${SHORT_SHA}"
          echo "  Branch:     ${{ github.ref_name }}"
          echo ""
          echo "Snowflake App:"
          echo "  Package:    ${{ vars.SNOWFLAKE_APP_PACKAGE }}"
          echo "  Instance:   ${{ vars.SNOWFLAKE_APP_INSTANCE }}"
          echo ""
          echo "Infrastructure:"
          echo "  Database:   ${{ vars.SNOWFLAKE_DATABASE }}"
          echo "  Schema:     ${{ vars.SNOWFLAKE_SCHEMA }}"
          echo "  Pool:       ${{ vars.SNOWFLAKE_COMPUTE_POOL }}"
          echo ""
          echo "Image Tag:    ${SHORT_SHA}"
          echo ""
          echo "=========================================="
          echo "  Application URL: ${{ steps.url.outputs.app_url }}"
          echo "=========================================="
